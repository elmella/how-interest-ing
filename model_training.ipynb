{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df, col_split):\n",
    "    continuous_cols = df.columns[col_split:]\n",
    "    categorical_cols = df.columns[:col_split]\n",
    "\n",
    "    # Standardizing the continuous features\n",
    "    scaler = StandardScaler()\n",
    "    df[continuous_cols] = scaler.fit_transform(df[continuous_cols])\n",
    "\n",
    "    # Applying One-Hot Encoding to categorical features\n",
    "    encoder = ColumnTransformer(transformers=[('cat', OneHotEncoder(sparse_output=True), categorical_cols)], remainder='passthrough')\n",
    "    return encoder.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('beta_dates/beta_data_7_60.csv', index_col=0)\n",
    "    y = pd.read_csv('beta_dates/true_labels.csv', index_col=0).values[:,0]\n",
    "    y = y + 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "# create a pipeline for XGBoost, FAMD, Random Forests, and Multiclass logistic regression\n",
    "pipe = Pipeline([\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('xgb', xgb.XGBClassifier(objective='multi:softmax', random_state=42)),\n",
    "        ])\n",
    "\n",
    "# create a parameter grid for the pipeline\n",
    "\n",
    "param_grid = {\n",
    "        'svd__n_components': [3,4,5],\n",
    "        'xgb__n_estimators': [80, 110, 200],  # Reduced number of trees\n",
    "        'xgb__learning_rate': [0.01, 0.5, 0.1, 1],  # Expanded range with a lower bound\n",
    "        'xgb__max_depth': [3,4],  # Shallower trees considering fewer components\n",
    "        'xgb__min_child_weight': [2, 4, 7],  # Adjusted values for instance weight\n",
    "        'xgb__gamma': [0.3, 0.5],  # Slightly expanded range for loss reduction\n",
    "        'xgb__subsample': [0.5, 0.7, 0.8],  # Adjusted subsample ratio\n",
    "        'xgb__colsample_bytree': [0.8, 1],  # Adjusted subsample ratio of columns\n",
    "        'xgb__reg_alpha': [1,2,3],  # Adjusted L1 regularization term\n",
    "        'xgb__reg_lambda': [1,2,3],  # Adjusted L2 regularization term\n",
    "        }\n",
    "\n",
    "# perform grid search\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# train model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "# create a pipeline for XGBoost, FAMD, Random Forests, and Multiclass logistic regression\n",
    "pipe = Pipeline([\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('xgb', xgb.XGBClassifier(objective='multi:softmax', random_state=42)),\n",
    "        ])\n",
    "\n",
    "# create a parameter grid for the pipeline\n",
    "\n",
    "param_grid = {\n",
    "'svd__n_components': 5,\n",
    " 'xgb__colsample_bytree': 0.8, \n",
    " 'xgb__gamma': 0.5, \n",
    " 'xgb__learning_rate': 0.1,\n",
    "   'xgb__max_depth': 3, \n",
    "   'xgb__min_child_weight': 2, \n",
    "   'xgb__n_estimators': 200, \n",
    "   'xgb__reg_alpha': 1, \n",
    "   'xgb__reg_lambda': 2, \n",
    "   'xgb__subsample': 0.7}\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe.set_params(**param_grid).fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "pipe = Pipeline([\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('rf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "        'svd__n_components': [3,4,5],\n",
    "        'rf__n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "        'rf__max_depth': [10, 20, 30],  # Maximum depth of each tree\n",
    "        'rf__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "        'rf__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
    "        'rf__max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# perform grid search\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# train model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('logreg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "        'svd__n_components': [3,4,5],\n",
    "        'logreg__C': [0.1, 1, 10, 100],\n",
    "        'logreg__penalty': ['l1', 'l2'],\n",
    "        'logreg__multi_class': ['ovr', 'multinomial'],\n",
    "        'logreg__solver': ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# perform grid search\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# train model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "print(grid_search.cv_results_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
