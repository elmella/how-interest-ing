{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('master_data.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.loc['1989-08-23':] #df = df.loc['1989-07-7':]\n",
    "df['mom'] = -df['mom_d'] + df['mom_u']\n",
    "df = df.drop(columns=['mom_u', 'mom_d'])\n",
    "df['label_day'] = ~df['decision'].isna()\n",
    "df = df.fillna(method='ffill')\n",
    "df = df.iloc[1:]\n",
    "df.to_csv('master_data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do...\n",
    "fix the decision column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns\n",
    "monthly = ['pce','ue','cars','house','cli','exports','rgdp','gdpd','veloc', 'ffr','mich']\n",
    "labels = ['decision', 'ffr', 'change']\n",
    "daily = ['spx','usd', 'loan']\n",
    "categorical = ['fed_party','potus_party','recess', 'mom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label_day'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union of all columns\n",
    "all_cols = monthly + daily + categorical + labels\n",
    "shared = set(df.columns.intersection(all_cols).to_list())\n",
    "df_cols = df.columns.to_list()\n",
    "\n",
    "# find the unique values of all_cols\n",
    "unique_ourlabels = {col if col not in shared else None for col in all_cols}\n",
    "unique_dflabels = {col if col not in shared else None for col in df_cols}\n",
    "unique_ourlabels.remove(None)\n",
    "unique_dflabels.remove(None)\n",
    "display(unique_ourlabels)\n",
    "display(unique_dflabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill all nan values\n",
    "def collapse(df, key = 'label_day', start = 7, end = 60, cat_col = [], daily_col = [], other = [], labels = []):\n",
    "    # Get our different dataframes\n",
    "    categorical = df[cat_col]\n",
    "    daily = df[daily_col]\n",
    "    monthly = df[other]\n",
    "    keep = df[key]\n",
    "    labels = df[labels]\n",
    "\n",
    "    # create the windows\n",
    "    event_days = df[df[key]].index\n",
    "\n",
    "    ################## Handle Categorical and Label Data ##################\n",
    "    cat_collapsed = categorical[keep]\n",
    "    y_labels = labels[keep]\n",
    "\n",
    "    ################## Handle Monthly Data ##################\n",
    "    # Create event windows\n",
    "    windows = []\n",
    "    for day in event_days:\n",
    "        # Calculate start and end days of the window\n",
    "        start_day = day - pd.Timedelta(days=start)\n",
    "        end_day = day - pd.Timedelta(days=end)\n",
    "\n",
    "        # Ensure start_day is not before the start of the dataset\n",
    "        if end_day < df.index[0]:\n",
    "            end_day = df.index[0]\n",
    "\n",
    "        windows.append((start_day, end_day))\n",
    "\n",
    "    # Initialize a list to store aggregated data\n",
    "    aggregated_data = []\n",
    "\n",
    "    for (start_day, end_day) in windows:\n",
    "        # Select data within the window\n",
    "        window_data = monthly.loc[end_day:start_day]\n",
    "\n",
    "        # Apply your custom aggregation function\n",
    "        final_vals = window_data.loc[start_day]\n",
    "        change = final_vals - window_data.iloc[0]\n",
    "        # relabel the change columns to include a d_ prefix\n",
    "        change = change.rename(lambda x: 'd_' + x)\n",
    "\n",
    "        # concatenate the data horizontally\n",
    "        aggregated_window = pd.concat([final_vals, change], axis=0)\n",
    "        aggregated_data.append(aggregated_window)\n",
    "\n",
    "    # Combine aggregated data\n",
    "    aggregated_monthly = pd.concat(aggregated_data, axis=1).T\n",
    "    aggregated_monthly.index = event_days\n",
    "\n",
    "    ################## Handle Daily Data ##################\n",
    "    # define the model\n",
    "    model = linear_model.LinearRegression()\n",
    "    daily_agg = []\n",
    "\n",
    "    # Get the names of the features\n",
    "    daily_feat = daily.columns\n",
    "    b0_name = ['b0_' + feat for feat in daily_feat]\n",
    "    b1_name = ['b1_' + feat for feat in daily_feat]\n",
    "\n",
    "    for (start_day, end_day) in windows:\n",
    "        # Select data within the window\n",
    "        window_data = daily.loc[end_day:start_day]\n",
    "        time = np.arange(len(window_data)).reshape(-1, 1)\n",
    "\n",
    "        # Initialize lists to store betas for each feature\n",
    "        beta0 = []\n",
    "        beta1 = []\n",
    "\n",
    "        # Loop through each feature and fit the model\n",
    "        for feat in daily_feat:\n",
    "            model.fit(time, window_data[feat])\n",
    "            beta0.append(model.intercept_)\n",
    "            beta1.append(model.coef_[0])\n",
    "\n",
    "        # Create DataFrames for betas\n",
    "        beta0_df = pd.DataFrame([beta0], columns=b0_name)\n",
    "        beta1_df = pd.DataFrame([beta1], columns=b1_name)\n",
    "\n",
    "        # concatenate the data horizontally\n",
    "        aggregated_window = pd.concat([beta0_df, beta1_df], axis=1)\n",
    "        daily_agg.append(aggregated_window)\n",
    "\n",
    "    # Combine aggregated data\n",
    "    aggregated_daily = pd.concat(daily_agg, axis=0)\n",
    "    aggregated_daily.index = event_days\n",
    "\n",
    "    ################## Combine Data ##################\n",
    "    # Combine all data\n",
    "    combined = pd.concat([cat_collapsed, aggregated_monthly, aggregated_daily], axis=1)\n",
    "    return combined, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ranges = [(7,60),(2,60),(7,120),(2,120),(7,42),(2,42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the date ranges and save the data\n",
    "for dates in date_ranges:\n",
    "    beta_data, label_data = collapse(df, start = dates[0], end = dates[1], cat_col = categorical, daily_col = daily, other = monthly, labels = labels)\n",
    "    beta_data.to_csv('beta_dates/beta_data_' + str(dates[0]) + '_' + str(dates[1]) + '.csv')\n",
    "label_data.to_csv('beta_dates/true_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50 (+/- 0.32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.51668244, 1.37445234, 0.23195717, 0.21567976, 1.46492275,\n",
       "       1.6639306 , 1.14258374, 1.10289998, 1.33558917, 0.49799004,\n",
       "       0.76665471, 0.84412662, 1.37882254, 1.00679942, 0.44264817,\n",
       "       0.05460396, 0.55191668, 0.52328102, 0.33205071, 0.22537767,\n",
       "       0.20761539, 0.59396924, 0.05909116, 0.64076393, 0.7290866 ,\n",
       "       0.15867522, 1.50184158, 0.75226609, 1.02462807, 0.21703594,\n",
       "       0.55084407, 0.17909169])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ue</th>\n",
       "      <td>1.663931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0_spx</th>\n",
       "      <td>1.501842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pce</th>\n",
       "      <td>1.464923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veloc</th>\n",
       "      <td>1.378823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potus_party</th>\n",
       "      <td>1.374452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cli</th>\n",
       "      <td>1.335589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cars</th>\n",
       "      <td>1.142584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0_loan</th>\n",
       "      <td>1.024628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffr</th>\n",
       "      <td>1.006799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef_size\n",
       "ue            1.663931\n",
       "b0_spx        1.501842\n",
       "pce           1.464923\n",
       "veloc         1.378823\n",
       "potus_party   1.374452\n",
       "cli           1.335589\n",
       "cars          1.142584\n",
       "house         1.102900\n",
       "b0_loan       1.024628\n",
       "ffr           1.006799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the right data\n",
    "data = pd.read_csv('beta_dates/beta_data_7_60.csv', index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "# Load in the labels\n",
    "labels = pd.read_csv('beta_dates/true_labels.csv', index_col=0)\n",
    "labels.index = pd.to_datetime(labels.index)\n",
    "\n",
    "# fit a sklearn softmax regression\n",
    "def cross_val(data, labels, folds = 6):\n",
    "    # define the model with an intercept and l2 regularization\n",
    "    model = linear_model.LogisticRegression(penalty='l2', fit_intercept=True, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(data, labels)\n",
    "\n",
    "    # get the cross validation scores\n",
    "    scores = cross_val_score(model, data, labels, cv=folds)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    # get the coefficients\n",
    "    coef = model.coef_\n",
    "    return coef\n",
    "\n",
    "\n",
    "#normalize the data\n",
    "def normalize(data):\n",
    "    return (data - data.mean()) / data.std()\n",
    "\n",
    "\n",
    "normalized_data = data.values\n",
    "normalized_data = normalize(data).values\n",
    "vals = cross_val(normalized_data, labels['decision'])\n",
    "coef_size = np.linalg.norm(vals, axis=0)\n",
    "display(coef_size)\n",
    "\n",
    "\n",
    "# what are the smallest coefficients of coef_size\n",
    "coef_size = pd.DataFrame(coef_size, index=data.columns)\n",
    "coef_size.columns = ['coef_size']\n",
    "coef_size = coef_size.sort_values(by='coef_size', ascending=False)\n",
    "display(coef_size.head(10))\n",
    "\n",
    "# save coef_size as a csv\n",
    "coef_size.to_csv('coef_size.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
