{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MaxAbsScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from prince import FAMD\n",
    "from scipy import sparse\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df, col_split):\n",
    "    \"\"\"\n",
    "    Prepares the data for the model by standardizing the continuous features, \n",
    "    converting the categorical features to strings, \n",
    "    and converting sparse columns to a dense format for FAMD.\n",
    "    \"\"\"\n",
    "    categorical_cols = df.columns[:col_split]\n",
    "\n",
    "    # converting the categorical features to strings\n",
    "    df[categorical_cols] = df[categorical_cols].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_data(data_address='beta_dates/beta_data_7_60.csv', label_address='beta_dates/true_labels.csv'):\n",
    "    df = pd.read_csv(data_address, index_col=0)\n",
    "    y = pd.read_csv(label_address, index_col=0).values[:,0]\n",
    "    y = y + 1\n",
    "    X = encoder(df, 4)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def load_data_cv(data_address='beta_dates/beta_data_7_60.csv', label_address='beta_dates/true_labels.csv'):\n",
    "    df = pd.read_csv(data_address, index_col=0)\n",
    "    y = pd.read_csv(label_address, index_col=0).values[:,0]\n",
    "    y = y + 1\n",
    "    X = encoder(df, 4)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'rf__max_depth': 3, 'rf__max_features': 0.6639830714160453, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 8, 'rf__n_estimators': 143}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.14      0.20         7\n",
      "         1.0       0.74      0.92      0.82        38\n",
      "         2.0       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.63      0.49      0.52        55\n",
      "weighted avg       0.70      0.73      0.69        55\n",
      "\n",
      "Accuracy: 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.73      0.95      0.83        38\n",
      "         2.0       0.80      0.36      0.50        11\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.51      0.44      0.44        55\n",
      "weighted avg       0.67      0.73      0.67        55\n",
      "\n",
      "Accuracy: 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         6\n",
      "         1.0       0.81      0.92      0.86        38\n",
      "         2.0       0.70      0.64      0.67        11\n",
      "\n",
      "    accuracy                           0.80        55\n",
      "   macro avg       0.84      0.63      0.68        55\n",
      "weighted avg       0.81      0.80      0.78        55\n",
      "\n",
      "Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.57      0.62         7\n",
      "         1.0       0.83      0.92      0.87        37\n",
      "         2.0       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.82        55\n",
      "   macro avg       0.79      0.71      0.74        55\n",
      "weighted avg       0.82      0.82      0.81        55\n",
      "\n",
      "Accuracy: 0.8181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.43      0.55         7\n",
      "         1.0       0.78      0.95      0.85        37\n",
      "         2.0       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.78        54\n",
      "   macro avg       0.78      0.59      0.64        54\n",
      "weighted avg       0.78      0.78      0.75        54\n",
      "\n",
      "Accuracy: 0.7777777777777778\n",
      "Average Accuracy: 0.7701010101010102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from prince import FAMD  # Ensure prince is installed\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Number of splits for K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Load your data\n",
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "# Perform FAMD on the dataset\n",
    "famd = FAMD(n_components=8)\n",
    "famd.fit(X)\n",
    "X = famd.transform(X)\n",
    "\n",
    "# Create a pipeline with the best parameters\n",
    "pipe = Pipeline([\n",
    "    ('scaler1', MaxAbsScaler()),\n",
    "    ('scaler2', MaxAbsScaler()),  # Consider if you really need two MaxAbsScalers\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.55, min_samples_leaf=6, min_samples_split=17, n_estimators=100))\n",
    "])\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "accuracy_scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the pipeline to the training data\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    accuracy_scores.append(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Average Accuracy:\", np.mean(accuracy_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[213], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# create a pipeline with the best parameters\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier()),\n\u001b[1;32m     14\u001b[0m ])\n\u001b[0;32m---> 16\u001b[0m pipe\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mparams\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Perform K-Fold Cross-Validation\u001b[39;00m\n\u001b[1;32m     20\u001b[0m accuracy_scores \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of splits for K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "famd = FAMD(n_components=8)\n",
    "famd.fit(X)\n",
    "X = famd.transform(X)\n",
    "\n",
    "# create a pipeline with the best parameters\n",
    "pipe = Pipeline([\n",
    "    ('rf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipe.set_params(**params)\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "\n",
    "accuracy_scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the pipeline to the training data\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    accuracy_scores.append(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Average Accuracy:\", np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy dropping 'fed_party': 0.7608047138047139\n",
      "Average Accuracy dropping 'potus_party': 0.7447171717171717\n",
      "Average Accuracy dropping 'recess': 0.7534175084175084\n",
      "Average Accuracy dropping 'mom': 0.7231683501683503\n",
      "Average Accuracy dropping 'pce': 0.763888888888889\n",
      "Average Accuracy dropping 'ue': 0.7665521885521887\n",
      "Average Accuracy dropping 'cars': 0.7761010101010102\n",
      "Average Accuracy dropping 'house': 0.7695084175084175\n",
      "Average Accuracy dropping 'cli': 0.7819090909090909\n",
      "Average Accuracy dropping 'exports': 0.7817542087542088\n",
      "Average Accuracy dropping 'rgdp': 0.7745521885521887\n",
      "Average Accuracy dropping 'gdpd': 0.7637508417508418\n",
      "Average Accuracy dropping 'veloc': 0.7805353535353536\n",
      "Average Accuracy dropping 'ffr': 0.7824814814814814\n",
      "Average Accuracy dropping 'mich': 0.7782693602693603\n",
      "Average Accuracy dropping 'd_pce': 0.7841616161616162\n",
      "Average Accuracy dropping 'd_ue': 0.7866666666666667\n",
      "Average Accuracy dropping 'd_cars': 0.7835454545454545\n",
      "Average Accuracy dropping 'd_house': 0.7819191919191919\n",
      "Average Accuracy dropping 'd_cli': 0.7844848484848485\n",
      "Average Accuracy dropping 'd_exports': 0.7846498316498317\n",
      "Average Accuracy dropping 'd_rgdp': 0.7921582491582491\n",
      "Average Accuracy dropping 'd_gdpd': 0.7894309764309765\n",
      "Average Accuracy dropping 'd_veloc': 0.7703063973063973\n",
      "Average Accuracy dropping 'd_ffr': 0.782959595959596\n",
      "Average Accuracy dropping 'd_mich': 0.7868484848484849\n",
      "Average Accuracy dropping 'b0_spx': 0.7859360269360269\n",
      "Average Accuracy dropping 'b0_usd': 0.7846464646464646\n",
      "Average Accuracy dropping 'b0_loan': 0.7815892255892256\n",
      "Average Accuracy dropping 'b1_spx': 0.7965151515151516\n",
      "Average Accuracy dropping 'b1_usd': 0.7923703703703705\n",
      "Average Accuracy dropping 'b1_loan': 0.7835858585858586\n",
      "Average Accuracy dropping 'No Feature Dropped': 0.7945016835016834\n",
      "Feature Drop Accuracies: {'fed_party': 0.7608047138047139, 'potus_party': 0.7447171717171717, 'recess': 0.7534175084175084, 'mom': 0.7231683501683503, 'pce': 0.763888888888889, 'ue': 0.7665521885521887, 'cars': 0.7761010101010102, 'house': 0.7695084175084175, 'cli': 0.7819090909090909, 'exports': 0.7817542087542088, 'rgdp': 0.7745521885521887, 'gdpd': 0.7637508417508418, 'veloc': 0.7805353535353536, 'ffr': 0.7824814814814814, 'mich': 0.7782693602693603, 'd_pce': 0.7841616161616162, 'd_ue': 0.7866666666666667, 'd_cars': 0.7835454545454545, 'd_house': 0.7819191919191919, 'd_cli': 0.7844848484848485, 'd_exports': 0.7846498316498317, 'd_rgdp': 0.7921582491582491, 'd_gdpd': 0.7894309764309765, 'd_veloc': 0.7703063973063973, 'd_ffr': 0.782959595959596, 'd_mich': 0.7868484848484849, 'b0_spx': 0.7859360269360269, 'b0_usd': 0.7846464646464646, 'b0_loan': 0.7815892255892256, 'b1_spx': 0.7965151515151516, 'b1_usd': 0.7923703703703705, 'b1_loan': 0.7835858585858586, 'No Feature Dropped': 0.7945016835016834}\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "# Original features plus the case of dropping no feature\n",
    "original_features = X.columns.tolist()\n",
    "original_features.append(None)  # Represents the case of dropping no feature\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Store average accuracies for each feature drop scenario\n",
    "feature_drop_accuracies = {}\n",
    "\n",
    "for drop_feature in original_features:\n",
    "    iteration_accuracies = []\n",
    "\n",
    "    for iteration in range(20):\n",
    "        # Drop one feature for this iteration, if specified\n",
    "        X_dropped = X.drop(columns=[drop_feature]) if drop_feature is not None else X\n",
    "\n",
    "        # Perform FAMD on the modified dataset\n",
    "        famd = FAMD(n_components=8)\n",
    "        famd.fit(X_dropped)\n",
    "        X_famd = famd.transform(X_dropped)\n",
    "\n",
    "        # Create a pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('rf', RandomForestClassifier()),  # Assuming params are set for RandomForest\n",
    "        ])\n",
    "\n",
    "        pipe.set_params(**params)\n",
    "\n",
    "        accuracy_scores = []\n",
    "        for train_index, test_index in skf.split(X_famd, y):\n",
    "            X_train, X_test = X_famd.iloc[train_index], X_famd.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Fit the pipeline to the training data\n",
    "            pipe.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            predictions = pipe.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            accuracy_scores.append(accuracy_score(y_test, predictions))\n",
    "\n",
    "        # Calculate average accuracy for this iteration\n",
    "        iteration_accuracies.append(np.mean(accuracy_scores))\n",
    "\n",
    "    # Calculate the overall average accuracy after dropping the feature\n",
    "    avg_accuracy = np.mean(iteration_accuracies)\n",
    "    feature_name = drop_feature if drop_feature is not None else \"No Feature Dropped\"\n",
    "    feature_drop_accuracies[feature_name] = avg_accuracy\n",
    "    print(f\"Average Accuracy dropping '{feature_name}':\", avg_accuracy)\n",
    "\n",
    "# Print overall results\n",
    "print(\"Feature Drop Accuracies:\", feature_drop_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.7898520084566596\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.7942917547568711\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.7942917547568711\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.7942917547568711\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.8081395348837208\n",
      "                                                                              \n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.55, min_samples_leaf=5, min_samples_split=6, n_estimators=100)\n",
      "Test score: 0.7454545454545455\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data\n",
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate and run the TPOT classifier\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Export the best pipeline\n",
    "tpot.export('best_pipeline.py')\n",
    "\n",
    "# Evaluate the final model\n",
    "print(\"Test score:\", tpot.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9708029197080292\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load your data\n",
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "# Specify K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Instantiate and run the TPOT classifier with K-Fold CV\n",
    "tpot = TPOTClassifier(cv=cv, n_jobs=-1)\n",
    "tpot.fit(X, y)\n",
    "\n",
    "# Export the best pipeline\n",
    "tpot.export('new_best_pipeline.py')\n",
    "\n",
    "# Evaluate the final model using the test score function\n",
    "# Note: The test score function will perform a separate train-test split internally\n",
    "print(\"Test score:\", tpot.score(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60         7\n",
      "         1.0       0.80      0.97      0.88        37\n",
      "         2.0       0.86      0.55      0.67        11\n",
      "\n",
      "    accuracy                           0.82        55\n",
      "   macro avg       0.89      0.65      0.71        55\n",
      "weighted avg       0.84      0.82      0.80        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from new_best_pipeline import exported_pipeline as new_model\n",
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "# split the data into training and test sets\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# predict the labels on the test set\n",
    "predictions = new_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('famd_data.csv', index_col=0)\n",
    "y = data['target']\n",
    "X = data.drop(columns=['target'])\n",
    "\n",
    "# Specify K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Instantiate and run the TPOT classifier with K-Fold CV\n",
    "tpot = TPOTClassifier(cv=cv, n_jobs=-1)\n",
    "tpot.fit(X, y)\n",
    "\n",
    "# Export the best pipeline\n",
    "tpot.export('famd_pipeline.py')\n",
    "\n",
    "# Evaluate the final model using the test score function\n",
    "# Note: The test score function will perform a separate train-test split internally\n",
    "print(\"Test score:\", tpot.score(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.56      0.71         9\n",
      "         1.0       0.85      0.94      0.89        31\n",
      "         2.0       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.85        55\n",
      "   macro avg       0.89      0.79      0.82        55\n",
      "weighted avg       0.87      0.85      0.85        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('famd_data.csv', index_col=0)\n",
    "y = X['target']\n",
    "X = X.drop(columns=['target'])\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_famd, y, test_size=0.2)\n",
    "\n",
    "# predict the labels on the test set\n",
    "predictions = tpot.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- target\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[341], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mfamd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# split the data into training and test sets\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# predict the labels on the test set\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, predictions))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    512\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1246\u001b[0m, in \u001b[0;36mMaxAbsScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scale the data.\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \n\u001b[1;32m   1235\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;124;03m    Transformed array.\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1246\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1256\u001b[0m     inplace_column_scale(X, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- target\n"
     ]
    }
   ],
   "source": [
    "# Import the exported pipeline\n",
    "from famd_best_pipeline import exported_pipeline as famd_model\n",
    "\n",
    "X = pd.read_csv('famd_data.csv', index_col=0)\n",
    "y = X['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "predictions = famd_model.predict(X_test)\n",
    "\n",
    "# split the data into training and test sets\n",
    "\n",
    "# predict the labels on the test set\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.72      1.00      0.84        38\n",
      "         2.0       1.00      0.20      0.33        10\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.57      0.40      0.39        55\n",
      "weighted avg       0.68      0.73      0.64        55\n",
      "\n",
      "Accuracy: 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29         6\n",
      "         1.0       0.72      1.00      0.84        38\n",
      "         2.0       1.00      0.09      0.17        11\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.91      0.42      0.43        55\n",
      "weighted avg       0.80      0.73      0.64        55\n",
      "\n",
      "Accuracy: 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29         6\n",
      "         1.0       0.71      0.97      0.82        38\n",
      "         2.0       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.71        55\n",
      "   macro avg       0.74      0.41      0.42        55\n",
      "weighted avg       0.70      0.71      0.63        55\n",
      "\n",
      "Accuracy: 0.7090909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.14      0.25         7\n",
      "         1.0       0.73      1.00      0.84        37\n",
      "         2.0       1.00      0.27      0.43        11\n",
      "\n",
      "    accuracy                           0.75        55\n",
      "   macro avg       0.91      0.47      0.51        55\n",
      "weighted avg       0.82      0.75      0.68        55\n",
      "\n",
      "Accuracy: 0.7454545454545455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.73      1.00      0.84        37\n",
      "         2.0       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.74        54\n",
      "   macro avg       0.58      0.43      0.43        54\n",
      "weighted avg       0.68      0.74      0.66        54\n",
      "\n",
      "Accuracy: 0.7407407407407407\n",
      "Average Accuracy: 0.7299663299663299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tpot_params = {'rf__bootstrap': True, 'rf__criterion': 'gini', 'rf__max_depth': 3, 'rf__max_features': 0.15000000000000002, 'rf__min_samples_leaf': 6, 'rf__min_samples_split': 16, 'rf__n_estimators': 100}\n",
    "\n",
    "# Number of splits for K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "X, y = load_data_cv('beta_dates/beta_data_2_42.csv', 'beta_dates/true_labels.csv')\n",
    "\n",
    "famd = FAMD(n_components=8)\n",
    "famd.fit(X)\n",
    "X = famd.transform(X)\n",
    "\n",
    "# create a pipeline with the best parameters\n",
    "pipe = Pipeline([\n",
    "    ('rf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipe.set_params(**tpot_params)\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "\n",
    "accuracy_scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the pipeline to the training data\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    accuracy_scores.append(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Average Accuracy:\", np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782608695652174"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from tpot.builtins import ZeroCount\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(X, y, random_state=None)\n",
    "\n",
    "# Average CV score on the training set was: 0.8176430976430977\n",
    "exported_pipeline = make_pipeline(\n",
    "    MaxAbsScaler(),\n",
    "    ZeroCount(),\n",
    "    RandomForestClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.2, min_samples_leaf=4, min_samples_split=5, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "accuracy_score(testing_target, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
